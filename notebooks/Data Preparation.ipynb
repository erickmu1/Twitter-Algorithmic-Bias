{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Copyright 2021 Twitter, Inc.\n",
    "SPDX-License-Identifier: Apache-2.0\n",
    "```\n",
    "\n",
    "## Collect analysis data from Wikidata\n",
    "\n",
    "Save the output of the query run on https://query.wikidata.org/ as described in the paper with the name `dataset.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME_DIR = Path(\"../\").expanduser()\n",
    "sys.path.append(str(HOME_DIR / \"src\"))\n",
    "data_dir = HOME_DIR / Path(\"./data/\")\n",
    "data_dir.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_dir / \"./dataset.json\") as fp:\n",
    "    wikidata_data = json.load(fp)\n",
    "\n",
    "len(wikidata_data[\"results\"][\"bindings\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikidata_data[\"results\"][\"bindings\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikidata_data[\"results\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikidata_data[\"results\"][\"bindings\"][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikidata_data[\"results\"][\"bindings\"][0][\"human\"][\"value\"].rsplit(\"/\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REQUIRED_COLS = [\n",
    "    \"human\",\n",
    "    \"image\",\n",
    "    \"sex_or_gender\",\n",
    "    \"ethnic_group\",\n",
    "    \"occupation\",\n",
    "    \"loc_aid\",\n",
    "]\n",
    "\n",
    "\n",
    "def parse_row(row):\n",
    "    data = {}\n",
    "    for c in REQUIRED_COLS:\n",
    "        value = row[c][\"value\"]\n",
    "        if row[c][\"type\"] == \"uri\":\n",
    "            value = value.rsplit(\"/\", 1)[-1]\n",
    "        data[c] = value\n",
    "    url = row[\"url\"]\n",
    "    extension = Path(url.rsplit(\"/\", 1)[-1]).suffix\n",
    "    local_path = f\"{data['human']}{extension}\"\n",
    "    data[\"url\"] = url\n",
    "    data[\"local_path\"] = local_path\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_row(wikidata_data[\"results\"][\"bindings\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([parse_row(row) for row in wikidata_data[\"results\"][\"bindings\"]])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gather images for all rows in `df`\n",
    "\n",
    "Put the required images for each wikidata id in `df` into the `OUTPUT_DIR` using the file name specified via the column `local_path`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = Path(data_dir / \"./images/\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "df[\"file_exists\"] = df[\"local_path\"].apply(lambda x: (OUTPUT_DIR / x).exists())\n",
    "df.file_exists.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.file_exists.value_counts()[False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After putting all images in the folder run the next cell to update the dataframe with file status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"file_exists\"] = df[\"local_path\"].apply(lambda x: (OUTPUT_DIR / x).exists())\n",
    "df.file_exists.value_counts()[False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(OUTPUT_DIR.glob(\"./*\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.file_exists.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"ethnic_group\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(data_dir / \"./dataset.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:image-crop-analysis]",
   "language": "python",
   "name": "conda-env-image-crop-analysis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
