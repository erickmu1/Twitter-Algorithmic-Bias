{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import logging\n",
    "import shlex\n",
    "import subprocess\n",
    "import sys\n",
    "from collections import namedtuple\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.collections import PatchCollection\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "logging.basicConfig(level=logging.ERROR)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import platform\n",
    "\n",
    "BIN_MAPS = {\"Darwin\": \"mac\", \"Linux\": \"linux\"}\n",
    "\n",
    "HOME_DIR = Path(\"../\").expanduser()\n",
    "\n",
    "try:\n",
    "    import google.colab\n",
    "    ! pip install pandas scikit-learn scikit-image statsmodels requests dash\n",
    "    ! [[ -d image-crop-analysis ]] || git clone https://github.com/twitter-research/image-crop-analysis.git\n",
    "    HOME_DIR = Path(\"./image-crop-analysis\").expanduser()\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "\n",
    "sys.path.append(str(HOME_DIR / \"src\"))\n",
    "bin_dir = HOME_DIR / Path(\"./bin\")\n",
    "bin_path = bin_dir / BIN_MAPS[platform.system()] / \"candidate_crops\"\n",
    "model_path = bin_dir / \"fastgaze.vxm\"\n",
    "data_dir = HOME_DIR / Path(\"./HALT_data/\")  # DATA directory\n",
    "print(\"Data directory exists:\", data_dir.exists())\n",
    "\n",
    "save_dir = HOME_DIR / Path(\"./HALT_results/\")   # SAVE directory\n",
    "print(\"Save directory exists:\", save_dir.exists())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Load Twitter's Saliencey + Cropping Model\n",
    "from crop_api import ImageSaliencyModel, is_symmetric, parse_output, reservoir_sampling\n",
    "\n",
    "model = ImageSaliencyModel(crop_binary_path=bin_path, crop_model_path=model_path)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "list(data_dir.glob(\"./*.jpg\"))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Do not display plots\n",
    "plt.ioff()\n",
    "\n",
    "# Run Algorithm on all Images in the Folder\n",
    "for img_path in data_dir.glob(\"*.jpg\"):\n",
    "    print(img_path)\n",
    "    model.plot_img_crops(img_path)\n",
    "\n",
    "    # Save resulting figure (which is not displayed)\n",
    "    plt.savefig(save_dir / img_path.name, bbox_inches=\"tight\")"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('image-crop-analysis': conda)"
  },
  "interpreter": {
   "hash": "60c6d1f01a6b86d97954e500cba66969566fa382f3ba32c579fe3b55289dceb9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}